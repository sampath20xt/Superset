from pymongo import MongoClient
from langchain_mongodb import MongoDBAtlasVectorSearch
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langgraph.graph import StateGraph
from langgraph.checkpoint.sqlite import SqliteSaver
from langchain_groq import ChatGroq
from langchain_core.prompts import PromptTemplate
from dotenv import load_dotenv, find_dotenv
import pandas as pd
import os

# Load environment variables
load_dotenv(find_dotenv())

MONGO_URI = os.getenv("MONGO_URI")  # Format: mongodb+srv://user:password@cluster.mongodb.net/
MONGO_DB = "rag_system"
MONGO_COLLECTION = "csv_embeddings"
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# Initialize LLM and Embeddings
llm_model = ChatGroq(model="llama-3.3-70b-versatile")
embedding_model = GoogleGenerativeAIEmbeddings(model="models/embedding-001", google_api_key=GOOGLE_API_KEY)

# Connect to MongoDB
client = MongoClient(MONGO_URI)
db = client[MONGO_DB]
collection = db[MONGO_COLLECTION]

# Ensure MongoDB Index for Vector Search
def setup_mongodb_index():
    collection.create_index([("embedding", "2dsphere")])  # Ensure MongoDB supports vector retrieval
    print("MongoDB Vector Index Created!")

# Process CSV and Store Data in MongoDB
def process_csv_and_store_embeddings(csv_path):
    df = pd.read_csv(csv_path)
    
    for _, row in df.iterrows():
        row_text = " ".join([str(value) for value in row.values])  # Convert row to text
        embedding = embedding_model.embed_query(row_text)  # Generate embedding

        collection.insert_one({"text": row_text, "embedding": embedding})

    print("CSV Data Processed and Stored in MongoDB")

# Setup MongoDB Vector Search
def setup_mongodb_retriever():
    return MongoDBAtlasVectorSearch(
        mongo_uri=MONGO_URI,
        db_name=MONGO_DB,
        collection_name=MONGO_COLLECTION,
        embedding_function=embedding_model,
        similarity_search_kwargs={"k": 5},
    ).as_retriever()

# Retrieve Documents from MongoDB
def retrieve_documents(state):
    query = state.query
    query_embedding = embedding_model.embed_query(query)  # Convert query to embedding

    # Find the most similar documents in MongoDB
    results = collection.find().sort(
        [("embedding", {"$meta": "vectorSearch", "vector": query_embedding})]
    ).limit(5)

    context = "\n".join([doc["text"] for doc in results]) if results else None
    return {"query": query, "context": context}

# Generate Response Using LLM
def generate_response(state):
    if state["context"]:
        response = llm_model.invoke(
            f"Answer the following question based on the provided context.\n\nContext: {state['context']}\n\nQuestion: {state['query']}"
        )
    else:
        response = "The answer is not available in the database."

    return {"query": state["query"], "context": state["context"], "response": response}

# Display Response
def display_response(state):
    print("\nRESULT:", state["response"])
    return state

# Define LangGraph Workflow
store = SqliteSaver("retrieval_state.db")
graph = StateGraph()

graph.add_node("retrieve_docs", retrieve_documents)
graph.add_node("generate_response", generate_response)
graph.add_node("display_response", display_response)

graph.set_entry_point("retrieve_docs")
graph.add_edge("retrieve_docs", "generate_response")
graph.add_edge("generate_response", "display_response")

retrieval_graph = graph.compile(checkpointer=store)

# Initialize Database and Store CSV Data
setup_mongodb_index()
csv_file_path = "data/inventory.csv"  # Replace with actual CSV file
process_csv_and_store_embeddings(csv_file_path)

# Setup Retriever
retriever = setup_mongodb_retriever()

# Run Query Processing Loop
while True:
    user_query = input("Write Query Here: ")
    if user_query.lower() in ["exit", "quit"]:
        break

    retrieval_graph.invoke({"query": user_query})
