import faiss
import numpy as np
from sentence_transformers import SentenceTransformer
import os
from vertexai import VertexAI
from vertexai.preview.generative_models import GenerativeModel, HarmCategory, HarmBlockThreshold

# Load the sentence-transformers model
embedding_model = SentenceTransformer("all-MiniLM-L6-v2")

# Set Google credentials and initialize Vertex AI
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "email-extraction-381718-3f73208ce3b71.json"
vertex_ai = VertexAI(project="email-extraction-381718", location="us-central1")
generative_multimodal_model = GenerativeModel("gemini-1.5-pro-001")

# Load and preprocess the txt file
def load_data(file_path):
    with open(file_path, "r", encoding="utf-8") as f:
        raw_text = f.readlines()

    # Convert to structured format if needed
    data = [line.strip() for line in raw_text if line.strip()]
    return data

# Generate embeddings for each text chunk
def generate_embeddings(text_list):
    embeddings = embedding_model.encode(text_list, convert_to_numpy=True)
    return embeddings

# Create FAISS index
def create_faiss_index(embeddings):
    dim = embeddings.shape[1]  # Dimension of embeddings
    index = faiss.IndexFlatL2(dim)
    index.add(embeddings)
    return index

# Perform vector search
def search_similar_texts(query, text_list, index, k=3):
    query_embedding = embedding_model.encode([query], convert_to_numpy=True)
    distances, indices = index.search(query_embedding, k)
    results = [text_list[i] for i in indices[0] if i < len(text_list)]
    return results

# Query Gemini AI with retrieved context
def query_gemini(final_prompt):
    generation_config = {
        "max_output_tokens": 8192,
        "temperature": 0.5,
        "top_p": 0.8,
    }

    safety_settings = {
        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,
        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,
        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,
        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,
    }

    # Generate content from Gemini
    response = generative_multimodal_model.generate_content(
        prompt=final_prompt,
        generation_config=generation_config,
        safety_settings=safety_settings
    )

    return response.text

# Main execution
if __name__ == "__main__":
    while True:  # Allow multiple queries while keeping embeddings temporary
        # Load the new data each time
        file_path = "Data/output.csv"  # Replace with your file path
        text_data = load_data(file_path)

        # Generate embeddings for new data
        embeddings = generate_embeddings(text_data)

        # Create a temporary FAISS index (previous embeddings are lost)
        index = create_faiss_index(embeddings)

        # Take user input and perform retrieval
        user_query = input("\nEnter your query (or type 'exit' to quit): ")
        if user_query.lower() == "exit":
            print("Exiting...")
            break

        relevant_texts = search_similar_texts(user_query, text_data, index)

        # Prepare the prompt for Gemini AI
        context = "\n".join(relevant_texts)
        final_prompt = f"Based on the following retrieved information, answer the question:\n\n{context}\n\nQuestion: {user_query}\n\nAnswer:"

        # Query Gemini AI and display the result
        response = query_gemini(final_prompt)
        print("\nGemini Response:\n", response)
